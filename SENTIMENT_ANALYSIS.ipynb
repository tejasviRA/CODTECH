{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bNh9iFSk2Esn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8ee351-7cb5-4bca-d8dd-5facba97a575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/jp797498e/twitter-entity-sentiment-analysis?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.99M/1.99M [00:00<00:00, 83.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jp797498e/twitter-entity-sentiment-analysis\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/root/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2'\n",
        "print(\"Files in dataset directory:\", os.listdir(dataset_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSvEhY9l2532",
        "outputId": "12c31aa4-be20-44f1-f9da-914c32c71ead"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in dataset directory: ['twitter_training.csv', 'twitter_validation.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/root/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2'\n",
        "\n",
        "# List all files in the dataset path\n",
        "files = os.listdir(dataset_path)\n",
        "print(\"Files in the dataset directory:\", files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvs2q1H23LFx",
        "outputId": "43c24f3f-ebc6-424a-98eb-e8b0086e0d5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the dataset directory: ['twitter_training.csv', 'twitter_validation.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path to the files\n",
        "dataset_path = '/root/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2'\n",
        "\n",
        "# Load the training and validation files\n",
        "train_file = os.path.join(dataset_path, 'twitter_training.csv')\n",
        "val_file = os.path.join(dataset_path, 'twitter_validation.csv')\n",
        "\n",
        "# Read the CSV files\n",
        "train_df = pd.read_csv(train_file)\n",
        "val_df = pd.read_csv(val_file)\n",
        "\n",
        "# Preview the data\n",
        "print(\"Training Data:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nValidation Data:\")\n",
        "print(val_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOdIOlQ23LJF",
        "outputId": "d5c79cfc-43b1-40a3-ea9e-de35c5243bd3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "   2401  Borderlands  Positive  \\\n",
            "0  2401  Borderlands  Positive   \n",
            "1  2401  Borderlands  Positive   \n",
            "2  2401  Borderlands  Positive   \n",
            "3  2401  Borderlands  Positive   \n",
            "4  2401  Borderlands  Positive   \n",
            "\n",
            "  im getting on borderlands and i will murder you all ,  \n",
            "0  I am coming to the borders and I will kill you...     \n",
            "1  im getting on borderlands and i will kill you ...     \n",
            "2  im coming on borderlands and i will murder you...     \n",
            "3  im getting on borderlands 2 and i will murder ...     \n",
            "4  im getting into borderlands and i can murder y...     \n",
            "\n",
            "Validation Data:\n",
            "   3364   Facebook Irrelevant  \\\n",
            "0   352     Amazon    Neutral   \n",
            "1  8312  Microsoft   Negative   \n",
            "2  4371      CS-GO   Negative   \n",
            "3  4433     Google    Neutral   \n",
            "4  6273       FIFA   Negative   \n",
            "\n",
            "  I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tom‚Äôs great auntie as ‚ÄòHayley can‚Äôt get out of bed‚Äô and told to his grandma, who now thinks I‚Äôm a lazy, terrible person ü§£  \n",
            "0  BBC News - Amazon boss Jeff Bezos rejects clai...                                                                                                                                                                                                  \n",
            "1  @Microsoft Why do I pay for WORD when it funct...                                                                                                                                                                                                  \n",
            "2  CSGO matchmaking is so full of closet hacking,...                                                                                                                                                                                                  \n",
            "3  Now the President is slapping Americans in the...                                                                                                                                                                                                  \n",
            "4  Hi @EAHelp I‚Äôve had Madeleine McCann in my cel...                                                                                                                                                                                                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Data Columns:\", train_df.columns)\n",
        "print(\"Validation Data Columns:\", val_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdkrMKuv6e5C",
        "outputId": "67710d27-fbd5-46a7-dc28-d6b38480b066"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Columns: Index(['2401', 'Borderlands', 'Positive',\n",
            "       'im getting on borderlands and i will murder you all ,'],\n",
            "      dtype='object')\n",
            "Validation Data Columns: Index(['3364', 'Facebook', 'Irrelevant',\n",
            "       'I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tom‚Äôs great auntie as ‚ÄòHayley can‚Äôt get out of bed‚Äô and told to his grandma, who now thinks I‚Äôm a lazy, terrible person ü§£'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns in the training dataset\n",
        "train_df.columns = ['id', 'entity', 'sentiment', 'text']\n",
        "\n",
        "# Rename columns in the validation dataset\n",
        "val_df.columns = ['id', 'entity', 'sentiment', 'text']\n"
      ],
      "metadata": {
        "id": "K69VPbX06fLM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['text'].dtypes)  # This should ideally be \"object\" for strings\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2uOituf7FOv",
        "outputId": "77e2419a-d32b-468c-de1b-cb813ae448b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all entries in the text column are strings\n",
        "train_df['text'] = train_df['text'].fillna('').astype(str)\n",
        "val_df['text'] = val_df['text'].fillna('').astype(str)\n",
        "\n",
        "# Apply the clean_text function\n",
        "train_df['cleaned_text'] = train_df['text'].apply(clean_text)\n",
        "val_df['cleaned_text'] = val_df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "YFu391sR7Fgz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'@\\w+', '', text)    # Remove mentions\n",
        "    text = re.sub(r'#\\w+', '', text)    # Remove hashtags\n",
        "    text = re.sub(r'\\W', ' ', text)     # Remove non-alphanumeric characters\n",
        "    text = text.lower().strip()         # Convert to lowercase\n",
        "    return text\n",
        "\n",
        "# Clean the text in training and validation datasets\n",
        "train_df['cleaned_text'] = train_df['text'].apply(clean_text)\n",
        "val_df['cleaned_text'] = val_df['text'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "gqtX_aZS6to5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all entries in the text column are strings\n",
        "train_df['text'] = train_df['text'].fillna('').astype(str)\n",
        "val_df['text'] = val_df['text'].fillna('').astype(str)\n",
        "\n",
        "# Apply the clean_text function\n",
        "train_df['cleaned_text'] = train_df['text'].apply(clean_text)\n",
        "val_df['cleaned_text'] = val_df['text'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "4xXKeG3y7K_y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncode\n",
        "\n",
        "# Initialize label encoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Encode sentiment labels\n",
        "train_df['sentiment_label'] = encoder.fit_transform(train_df['sentiment'])\n",
        "val_df['sentiment_label'] = encoder.transform(val_df['sentiment'])\n",
        "\n",
        "# Check the mapping\n",
        "print(\"Label Mapping:\", dict(zip(encoder.classes_, encoder.transform(encoder.classes_))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwQcO9Vo7TVT",
        "outputId": "87ce816d-2af2-4dd8-c179-a5af73d7f913"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Mapping: {'Irrelevant': 0, 'Negative': 1, 'Neutral': 2, 'Positive': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df['cleaned_text']\n",
        "y_train = train_df['sentiment_label']\n",
        "\n",
        "X_test = val_df['cleaned_text']\n",
        "y_test = val_df['sentiment_label']\n"
      ],
      "metadata": {
        "id": "O9zbn-ry7W7W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize vectorizer\n",
        "vectorizer = CountVectorizer(max_features=5000)\n",
        "\n",
        "# Fit and transform the training data, transform the validation data\n",
        "X_train_vectors = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_vectors = vectorizer.transform(X_test).toarray()\n"
      ],
      "metadata": {
        "id": "nqsGcIFI7cX-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_dim=X_train_vectors.shape[1]),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(encoder.classes_), activation='softmax')  # Multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_vectors, y_train, epochs=5, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un9FH0_H7iUx",
        "outputId": "334f0723-d114-493c-feee-9fe90587f378"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1867/1867\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - accuracy: 0.5048 - loss: 1.1379 - val_accuracy: 0.5101 - val_loss: 1.2340\n",
            "Epoch 2/5\n",
            "\u001b[1m1867/1867\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 12ms/step - accuracy: 0.7697 - loss: 0.6166 - val_accuracy: 0.5187 - val_loss: 1.4741\n",
            "Epoch 3/5\n",
            "\u001b[1m1867/1867\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8387 - loss: 0.4369 - val_accuracy: 0.5086 - val_loss: 1.7204\n",
            "Epoch 4/5\n",
            "\u001b[1m1867/1867\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8646 - loss: 0.3609 - val_accuracy: 0.5036 - val_loss: 1.9320\n",
            "Epoch 5/5\n",
            "\u001b[1m1867/1867\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.8824 - loss: 0.3164 - val_accuracy: 0.5034 - val_loss: 2.1550\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b7c50882b10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predict the sentiments\n",
        "y_pred = model.predict(X_test_vectors)\n",
        "y_pred_labels = y_pred.argmax(axis=1)\n",
        "\n",
        "# Print a classification report\n",
        "print(classification_report(y_test, y_pred_labels, target_names=encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhMeZGRK8heU",
        "outputId": "bf016562-3557-4d3a-fe34-a415062a2578"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.84      0.86      0.85       171\n",
            "    Negative       0.89      0.89      0.89       266\n",
            "     Neutral       0.92      0.88      0.90       285\n",
            "    Positive       0.88      0.91      0.90       277\n",
            "\n",
            "    accuracy                           0.89       999\n",
            "   macro avg       0.88      0.88      0.88       999\n",
            "weighted avg       0.89      0.89      0.89       999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    cleaned_text = clean_text(text)\n",
        "    vectorized_text = vectorizer.transform([cleaned_text]).toarray()\n",
        "    prediction = model.predict(vectorized_text).argmax(axis=1)\n",
        "    return encoder.inverse_transform(prediction)[0]\n",
        "#inverse helps turn numericals back to words\n",
        "\n",
        "# Test\n",
        "print(predict_sentiment(\"I absolutely love this game!\"))\n",
        "print(predict_sentiment(\"The customer service was bad.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTfwWNIn8hut",
        "outputId": "22b813ff-ae76-4825-ceb1-4c76b3a34c11"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
            "Positive\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('sentiment_model.h5')\n",
        "\n",
        "# Save the vectorizer using joblib or pickle\n",
        "import joblib\n",
        "joblib.dump(vectorizer, 'vectorizer.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zJSUT9z89Kx",
        "outputId": "66a54eaa-e714-48f6-c2de-9e4c9f88ab2d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}
